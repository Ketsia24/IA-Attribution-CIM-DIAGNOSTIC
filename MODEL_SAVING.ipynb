{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Charger les données\n",
    "# Supposons que data contient les données textuelles et labels les ICD10\n",
    "data=pd.read_csv('data.csv')\n",
    "# Prétraitement des données textuelles\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['RawText'])\n",
    "sequences = tokenizer.texts_to_sequences(data['RawText'])\n",
    "sequences = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# Encodage des labels ICD10\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(data[' ICD10'])\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construction du modèle\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=50000, output_dim=300, input_length=100))\n",
    "model.add(Bidirectional(GRU(256)))\n",
    "model.add(Dense(700, activation='relu'))\n",
    "model.add(Dense(14602, activation='softmax'))  # Assure-toi que le nombre de neurones correspond au nombre de classes ICD10\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"THEModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Perte sur l'ensemble de test:\", loss)\n",
    "print(\"Précision sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predire_code_icd():\n",
    "    # Récupérer le texte d'entrée de l'utilisateur\n",
    "    texte_entrée = input(\"Entrez votre texte ici : \")\n",
    "\n",
    "    # Procéder à la tokenisation et au padding\n",
    "    sequence_entrée = tokenizer.texts_to_sequences([texte_entrée])\n",
    "    sequence_padded = pad_sequences(sequence_entrée, maxlen=100)  # Assurez-vous que cela correspond à la longueur utilisée lors de l'entraînement\n",
    "\n",
    "    # Faire une prédiction avec le modèle\n",
    "    prediction = model.predict(sequence_padded)\n",
    "\n",
    "    # Obtenir l'indice de la classe la plus probable\n",
    "    indice_classe_predite = np.argmax(prediction, axis=-1)\n",
    "\n",
    "    # Convertir l'indice en code ICD\n",
    "    code_icd_predite = label_encoder.inverse_transform(indice_classe_predite)[0]\n",
    "\n",
    "    # Retourner ou imprimer le code ICD prédit\n",
    "    print(f\"Code ICD prédit: {code_icd_predite}\")\n",
    "\n",
    "# Appeler la fonction pour faire une prédiction basée sur l'entrée de l'utilisateur\n",
    "predire_code_icd()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
